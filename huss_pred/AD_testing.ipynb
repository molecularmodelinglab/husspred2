{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\anaconda3\\envs\\rdkit_env\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.5.1 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ricar\\anaconda3\\envs\\rdkit_env\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.5.1 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\ricar\\anaconda3\\envs\\rdkit_env\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.5.1 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "\n",
    "\"\"\"import glob\n",
    "import gzip\n",
    "import bz2\"\"\"\n",
    "import os\n",
    "#import _pickle as cPickle\n",
    "\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# god hates me so in my version of python I cannot supress these damn user warning so I do this nuclear option instead\n",
    "\"\"\"import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\"\"\"\n",
    "\n",
    "# for setting confidence-based AD:\n",
    "AD_THRESH = 0.6\n",
    "\n",
    "\n",
    "import joblib  # Ensure this import is at the beginning of your script\n",
    "\n",
    "\n",
    "MODEL_DIR = os.path.join(os.getcwd(), \"models\")  # Directory where models are stored\n",
    "\n",
    "MODEL_DICT = {\n",
    "    'Binary Sensitization': [joblib.load(os.path.join(MODEL_DIR, 'ss_DSA05_binary_morgan_r2_2048_svm_calibrated_with_threshold.joblib'))['model']],\n",
    "    'Multiclass Sensitization Potency': [joblib.load(os.path.join(MODEL_DIR, 'DSA05_mordred_rf_multiclass.joblib'))]\n",
    "}\n",
    "\n",
    "THRES_DICT = {\n",
    "    'Binary Sensitization': [joblib.load(os.path.join(MODEL_DIR, 'ss_DSA05_binary_morgan_r2_2048_svm_calibrated_with_threshold.joblib'))['threshold']],\n",
    "}\n",
    "\n",
    "# CHECK THIS\n",
    "AD_DICT = {\n",
    "    'Binary Sensitization': [joblib.load(os.path.join(MODEL_DIR, 'binary_AD.pkl'))],\n",
    "    'Multiclass Sensitization Potency': [joblib.load(os.path.join(MODEL_DIR, 'multiclass_AD.pkl'))],\n",
    "}\n",
    "\n",
    "FEATURES_DICT = {\n",
    "    'Binary Sensitization': [np.load(os.path.join(MODEL_DIR, 'selected_features_svm_binary.npy'), allow_pickle=True)],\n",
    "    'Multiclass Sensitization Potency': [np.load(os.path.join(MODEL_DIR, 'selected_features_rf_multiclass.npy'), allow_pickle=True)],\n",
    "}\n",
    "\n",
    "# lol I'm just like screw code readability sorry\n",
    "MODEL_DICT_INVERT = {str(v): key for key, val in MODEL_DICT.items() for v in val}\n",
    "\n",
    "CLASSIFICATION_DICT = {\n",
    "    'Binary Sensitization Call': {\n",
    "        0: \"Non-sensitizer\",\n",
    "        1: \"Sensitizer\"\n",
    "    },\n",
    "    'Multiclass Sensitization Potency': {\n",
    "        0: \"Non-sensitizer\",\n",
    "        1: \"Weak sensitizer\",\n",
    "        2: \"Strong sensitizer\",\n",
    "    }\n",
    "}\n",
    "\n",
    "AD_DICT_BOOL = {\n",
    "    True: \"Inside\",\n",
    "    False: \"Outside\"\n",
    "}\n",
    "\n",
    "\n",
    "def _get_AD_thresh(training_smiles, file_name):\n",
    "    fps = np.array([list(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi), radius=2, nBits=2048, useFeatures=False))\n",
    "                    for smi in training_smiles])\n",
    "\n",
    "    dists = pdist(fps)\n",
    "    mean_1 = dists.mean()\n",
    "    dists_2 = dists[np.where(dists < mean_1)]\n",
    "    mean_2 = dists_2.mean()\n",
    "    std_2 = dists_2.std()\n",
    "\n",
    "    threshold = mean_2 + (0.5 * std_2)\n",
    "\n",
    "    import pickle\n",
    "    pickle.dump((threshold, fps),  open(file_name, \"wb\"))\n",
    "\n",
    "    with open(file_name, \"wb\") as f:\n",
    "        pickle.dump((threshold, fps), f)\n",
    "\n",
    "\n",
    "def calc_ad(query_fp, ad_tuple):\n",
    "    dist = cdist(query_fp.reshape(1, -1), ad_tuple[1], \"euclidean\")\n",
    "    return (dist < ad_tuple[0]).any()\n",
    "\n",
    "\n",
    "\n",
    "def run_prediction_binary(model, smi, calculate_ad=True, ad_tup=None, threshold=0.5):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        model_data (_type_): _description_\n",
    "        smi (_type_): _description_\n",
    "        calculate_ad (bool, optional): _description_. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    fp = np.zeros((2048, 1))\n",
    "    # sub in your FP function\n",
    "    _fp = AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi), radius=2, nBits=2048, useFeatures=False)\n",
    "    DataStructs.ConvertToNumpyArray(_fp, fp)\n",
    "\n",
    "    selected_features = np.load(os.path.join(MODEL_DIR, 'selected_features_svm_binary.npy'))\n",
    "    fp_selected = fp[selected_features]\n",
    "\n",
    "    pred_proba = model.predict_proba(fp_selected.reshape(1, -1))[:, 1]\n",
    "    pred = 1 if pred_proba > threshold else 0\n",
    "\n",
    "    if pred == 0:\n",
    "        pred_proba = 1 - float(pred_proba)\n",
    "\n",
    "    # used to get proba of the inactive class if deemed inactive\n",
    "    # if pred == 0:\n",
    "    #     pred_proba = 1-pred_proba\n",
    "\n",
    "    if calculate_ad:\n",
    "        ad = calc_ad(fp, ad_tup)\n",
    "        return pred, pred_proba, ad\n",
    "    \n",
    "    else:\n",
    "        ad = False  # Set to True or False depending on how you want to interpret \"no AD calculation\"\n",
    "\n",
    "    return pred, float(pred_proba), \"\"\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from mordred import Calculator, descriptors\n",
    "\n",
    "def run_prediction_multiclass(model, smi, calculate_ad=True, ad_tup=None, threshold=0.5):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        model_data (_type_): _description_\n",
    "        smi (_type_): _description_\n",
    "        calculate_ad (bool, optional): _description_. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    fp_ad_arr = np.zeros((2048, 1))\n",
    "    # sub in your FP function\n",
    "    fp_ad = AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi), radius=2, nBits=2048, useFeatures=False)\n",
    "    DataStructs.ConvertToNumpyArray(fp_ad, fp_ad_arr)\n",
    "\n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "    mol = Chem.MolFromSmiles(smi)  # Convert SMILES to RDKit Mol object\n",
    "    if mol is None:\n",
    "        raise ValueError(f\"Invalid SMILES string: {smi}\")\n",
    "    \n",
    "    _fp = calc.pandas([mol])  # Pass the mol as a list\n",
    "\n",
    "    # Min-Max scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    fp = scaler.fit_transform(_fp)\n",
    "\n",
    "    # Load selected features with allow_pickle=True\n",
    "    selected_features = np.load(os.path.join(MODEL_DIR, 'selected_features_rf_multiclass.npy'), allow_pickle=True)\n",
    "\n",
    "    # Ensure selected_features are valid column names\n",
    "    # Filter the fp DataFrame to retain only the selected columns (features)\n",
    "    fp_selected = _fp[selected_features]\n",
    "\n",
    "    # Scale the selected features\n",
    "    fp_selected_scaled = scaler.fit_transform(fp_selected)\n",
    "\n",
    "    # Get probabilities for all classes (not just class 1)\n",
    "    pred_proba = model.predict_proba(fp_selected_scaled.reshape(1, -1))\n",
    "\n",
    "    # Get the class with the highest probability\n",
    "    pred = np.argmax(pred_proba)\n",
    "\n",
    "    # Probability of the predicted class\n",
    "    predicted_class_proba = pred_proba[0][pred]\n",
    "\n",
    "    if calculate_ad:\n",
    "        ad = calc_ad(fp_ad_arr, ad_tup)\n",
    "        return pred, predicted_class_proba, ad\n",
    "    \n",
    "    return pred, predicted_class_proba, \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_prob_map(model, smi):\n",
    "    def get_fp(mol, idx):\n",
    "        fps = np.zeros((2048, 1))\n",
    "        _fps = SimilarityMaps.GetMorganFingerprint(mol, idx, radius=2, nBits=2048)\n",
    "        DataStructs.ConvertToNumpyArray(_fps, fps)\n",
    "        return fps\n",
    "\n",
    "    def get_proba(fps):\n",
    "        return float(model.predict_proba(fps.reshape(1, -1))[:, 1])\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    fig, _ = SimilarityMaps.GetSimilarityMapForModel(mol, get_fp, get_proba)\n",
    "    imgdata = io.StringIO()\n",
    "    fig.savefig(imgdata, format='svg')\n",
    "    imgdata.seek(0)  # rewind the data\n",
    "    plt.savefig(imgdata, format=\"svg\", bbox_inches=\"tight\")\n",
    "\n",
    "    return imgdata.getvalue()\n",
    "\n",
    "\n",
    "def main(smi, calculate_ad=True, make_prop_img=False, **kwargs):\n",
    "    values = {}\n",
    "\n",
    "    for key, val in kwargs.items():\n",
    "        if key in MODEL_DICT.keys():  # check if this kwarg is for a model\n",
    "            if val:  # check if model is turned on\n",
    "                model = MODEL_DICT[key][0]  # Get the model\n",
    "                ad_tup = AD_DICT[key][0]\n",
    "\n",
    "                # Choose the appropriate prediction function\n",
    "                if key == 'Binary Sensitization':\n",
    "                    pred, pred_proba, ad = run_prediction_binary(model, smi, calculate_ad=calculate_ad, ad_tup=ad_tup)\n",
    "                elif key == 'Multiclass Sensitization Potency':\n",
    "                    pred, pred_proba, ad = run_prediction_multiclass(model, smi, calculate_ad=calculate_ad, ad_tup=ad_tup)\n",
    "\n",
    "                contrib_svg_str = \"\"\n",
    "                if make_prop_img:\n",
    "                    contrib_svg_str = get_prob_map(model, smi)\n",
    "\n",
    "                values[key] = [pred, float(pred_proba), AD_DICT_BOOL[ad], contrib_svg_str]\n",
    "\n",
    "    processed_results = []\n",
    "    for key, val in values.items():\n",
    "        # Use 'Binary Sensitization Call' for the classification dict key\n",
    "        classification_key = 'Binary Sensitization Call' if key == 'Binary Sensitization' else key\n",
    "        processed_results.append([key, CLASSIFICATION_DICT[classification_key][val[0]], val[1], val[2], val[3]])\n",
    "\n",
    "    return processed_results\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLD CODE - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricar\\AppData\\Local\\Temp\\ipykernel_11928\\1028292425.py:237: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  values[key] = [pred, float(pred_proba), AD_DICT_BOOL[ad], contrib_svg_str]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Binary Sensitization', 'Sensitizer', 0.8769790857195798, 'Inside', '']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_string = \"NC(=O)C1=CC=CC=C1\"\n",
    "results = main(smi=smiles_string, calculate_ad=True, make_prop_img=False, **{\"Binary Sensitization\": True})\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\anaconda3\\envs\\rdkit_env\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.5.1 when using version 1.4.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': SVC(C=453.40231050514495, gamma=0.0784644856439669, probability=True),\n",
       " 'threshold': 0.7803329871102571}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = joblib.load(\"models/ss_DSA05_binary_morgan_r2_2048_svm_calibrated_with_threshold.joblib\")  # Load the model\n",
    "print(type(model))  # Check the type of the loaded model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,   80,  222,  227,  283,  294,  389,  529,  573,  622,\n",
       "        650,  679,  691,  693,  694,  695,  759,  769,  807,  890,  926,\n",
       "        929, 1019, 1057, 1088, 1095, 1114, 1138, 1143, 1155, 1163, 1200,\n",
       "       1249, 1281, 1365, 1380, 1421, 1444, 1485, 1599, 1629, 1673, 1750,\n",
       "       1783, 1866, 1873, 1914, 1917, 1999], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_features_test = np.load(\"models/selected_features_svm_binary.npy\")  # Load the selected features for the model\n",
    "sel_features_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_load = joblib.load(\"models/DSA05_BINARY_SVM_x_train.pkl\")  # Load the training data\n",
    "type(training_load)\n",
    "len(training_load)\n",
    "training_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing AD Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def _get_AD_thresh(fps, file_name):\n",
    "    dists = pdist(fps)\n",
    "    mean_1 = dists.mean()\n",
    "    dists_2 = dists[np.where(dists < mean_1)]\n",
    "    mean_2 = dists_2.mean()\n",
    "    std_2 = dists_2.std()\n",
    "\n",
    "    threshold = mean_2 + (0.5 * std_2)\n",
    "\n",
    "    pickle.dump((threshold, fps),  open(file_name, \"wb\"))\n",
    "\n",
    "def read_sdf_and_save_ad_file(sdf_file, output_file):\n",
    "    suppl = Chem.SDMolSupplier(sdf_file)\n",
    "    molecules = [mol for mol in suppl if mol is not None]\n",
    "\n",
    "    fps = np.array([list(AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=2048, useFeatures=False))\n",
    "                    for mol in molecules])\n",
    "\n",
    "    _get_AD_thresh(fps, output_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname1 = \"../models/dataset_ss_DSA05_WES_GHS_BIN_Binary.sdf\"\n",
    "fname2 = \"../models/dataset_ss_DSA05_WES_GHS_SUB MC.sdf\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall FPs\n",
    "MODEL_DIR = os.path.join(os.path.dirname(\"../dev_tox\"), \"models\")  # Directory where models are stored\n",
    "sdf_file = fname1  # Replace with your SDF file path\n",
    "output_file = os.path.join(MODEL_DIR, 'binary_AD.pkl')  # Replace 'your_model_AD.pkl' with your desired output file name\n",
    "\n",
    "read_sdf_and_save_ad_file(sdf_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First TM FPs\n",
    "MODEL_DIR = os.path.join(os.path.dirname(\"../dev_tox\"), \"models\")  # Directory where models are stored\n",
    "sdf_file = fname2  # Replace with your SDF file path\n",
    "output_file = os.path.join(MODEL_DIR, 'multiclass_AD.pkl')  # Replace 'your_model_AD.pkl' with your desired output file name\n",
    "\n",
    "read_sdf_and_save_ad_file(sdf_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the data in the file: <class 'tuple'>\n",
      "Length of the data: 2\n",
      "Type of the first element: <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Assuming your function 'read_sdf_and_save_ad_file' has already been run and the output file has been created\n",
    "\n",
    "# Path to the output file\n",
    "MODEL_DIR = os.path.join(os.path.dirname(\"c:/Users/ricar/Documents/GitHub/dev-tox/dev_tox\"), \"models\")\n",
    "output_file = os.path.join(MODEL_DIR, 'binary_AD.pkl')\n",
    "\n",
    "# Load the output file\n",
    "with open(output_file, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Check and print the type of data\n",
    "print(f\"Type of the data in the file: {type(data)}\")\n",
    "\n",
    "# If you want to see more details about the content (like length if it's a list or tuple)\n",
    "if isinstance(data, (list, tuple)):\n",
    "    print(f\"Length of the data: {len(data)}\")\n",
    "    # To show the type of the first element in the tuple/list\n",
    "    print(f\"Type of the first element: {type(data[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _get_AD_thresh(training_smiles, file_name):\n",
    "    fps = np.array([list(AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi), radius=2, nBits=2048, useFeatures=False))\n",
    "                    for smi in training_smiles])\n",
    "\n",
    "    dists = pdist(fps)\n",
    "    mean_1 = dists.mean()\n",
    "    dists_2 = dists[np.where(dists < mean_1)]\n",
    "    mean_2 = dists_2.mean()\n",
    "    std_2 = dists_2.std()\n",
    "\n",
    "    threshold = mean_2 + (0.5 * std_2)\n",
    "\n",
    "    import pickle\n",
    "    pickle.dump((threshold, fps),  open(file_name, \"wb\"))\n",
    "\n",
    "\n",
    "def calc_ad(query_fp, ad_tuple):\n",
    "    dist = cdist(query_fp, ad_tuple[1], \"euclidean\")\n",
    "    return dist < ad_tuple[0]\n",
    "\n",
    "\n",
    "def run_prediction(model, smi, calculate_ad=True, ad_tup=None, threshold=0.5):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        model_data (_type_): _description_\n",
    "        smi (_type_): _description_\n",
    "        calculate_ad (bool, optional): _description_. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    fp = np.zeros((2048, 1))\n",
    "    # sub in your FP function\n",
    "    _fp = AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smi), radius=2, nBits=2048, useFeatures=False)\n",
    "    DataStructs.ConvertToNumpyArray(_fp, fp)\n",
    "\n",
    "    pred_proba = model.predict_proba(fp.reshape(1, -1))[:, 1]\n",
    "    pred = 1 if pred_proba > threshold else 0\n",
    "\n",
    "    if pred == 0:\n",
    "        pred_proba = 1 - float(pred_proba)\n",
    "\n",
    "    # used to get proba of the inactive class if deemed inactive\n",
    "    # if pred == 0:\n",
    "    #     pred_proba = 1-pred_proba\n",
    "\n",
    "    if calculate_ad:\n",
    "        ad = calc_ad(fp, ad_tup)\n",
    "        return pred, pred_proba, ad\n",
    "\n",
    "    return pred, float(pred_proba), \"\"\n",
    "\n",
    "\n",
    "def get_prob_map(model, smi):\n",
    "    def get_fp(mol, idx):\n",
    "        fps = np.zeros((2048, 1))\n",
    "        _fps = SimilarityMaps.GetMorganFingerprint(mol, idx, radius=3, nBits=2048)\n",
    "        DataStructs.ConvertToNumpyArray(_fps, fps)\n",
    "        return fps\n",
    "\n",
    "    def get_proba(fps):\n",
    "        return float(model.predict_proba(fps.reshape(1, -1))[:, 1])\n",
    "\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    fig, _ = SimilarityMaps.GetSimilarityMapForModel(mol, get_fp, get_proba)\n",
    "    imgdata = io.StringIO()\n",
    "    fig.savefig(imgdata, format='svg')\n",
    "    imgdata.seek(0)  # rewind the data\n",
    "    plt.savefig(imgdata, format=\"svg\", bbox_inches=\"tight\")\n",
    "\n",
    "    return imgdata.getvalue()\n",
    "\n",
    "\n",
    "def main(smi, calculate_ad=True, make_prop_img=False, **kwargs):\n",
    "    values = {}\n",
    "\n",
    "    for key, val in kwargs.items():\n",
    "        if key in MODEL_DICT.keys():  # check if this kwarg is for a model\n",
    "            if val:  # check if model is turned on\n",
    "                model = MODEL_DICT[key][0]  # Get the model file path\n",
    "                ad_tup = AD_DICT[key][0]\n",
    "                # print(f\"Loading model from: {model_file}\")\n",
    "                # model = joblib.load(model_file)  # load the model\n",
    "\n",
    "                pred, pred_proba, ad = run_prediction(model, smi, calculate_ad=calculate_ad, ad_tup=ad_tup)\n",
    "\n",
    "                contrib_svg_str = \"\"\n",
    "                if make_prop_img:\n",
    "                    contrib_svg_str = get_prob_map(model, smi)\n",
    "\n",
    "                values[key] = [pred, float(pred_proba), AD_DICT[ad > AD_THRESH], contrib_svg_str]\n",
    "\n",
    "    processed_results = []\n",
    "    for key, val in values.items():\n",
    "        processed_results.append([key, CLASSIFICATION_DICT[key][val[0]], val[1], val[2], val[3]])\n",
    "\n",
    "    return processed_results\n",
    "\n",
    "\n",
    "# def write_csv_file(smiles_list, calculate_ad=False):\n",
    "#     headers = list(MODEL_DICT.keys())\n",
    "#\n",
    "#     if calculate_ad:\n",
    "#         headers = headers + [_ + \"_AD\" for _ in headers]\n",
    "#\n",
    "#     string_file = StringIO()\n",
    "#     writer = csv.DictWriter(string_file, fieldnames=['SMILES', *headers])\n",
    "#     writer.writeheader()\n",
    "#\n",
    "#     for smiles in tqdm(smiles_list):\n",
    "#         molecule = MolFromSmiles(smiles)\n",
    "#\n",
    "#         row = {'SMILES': smiles}\n",
    "#\n",
    "#         if molecule is None:\n",
    "#             row['SMILES'] = f\"(invalid){smiles}\"\n",
    "#             writer.writerow(row)\n",
    "#             continue\n",
    "#\n",
    "#         data = main(smiles, calculate_ad=calculate_ad, **MODEL_DICT)\n",
    "#\n",
    "#         for model_name, pred, pred_proba, ad, _ in data:\n",
    "#             try:\n",
    "#                 pred_proba = float(pred_proba[:-1]) / 100  # covert back to 0-1 float\n",
    "#                 row[\n",
    "#                     model_name] = pred_proba if pred == 1 else 1 - pred_proba  # this is to make sure its proba for class 1\n",
    "#             except ValueError:\n",
    "#                 row[model_name] = \"No prediction\"  # if pred_proba is string skip\n",
    "#             if calculate_ad:\n",
    "#                 row[model_name + \"_AD\"] = ad\n",
    "#\n",
    "#         writer.writerow(row)\n",
    "#\n",
    "#     return string_file.getvalue()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     import argparse\n",
    "#     import csv\n",
    "#     from io import StringIO\n",
    "#     from rdkit.Chem import MolFromSmiles\n",
    "#     from tqdm import tqdm\n",
    "#\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--infile\", type=str, required=True,\n",
    "#                         help=\"location to csv of SMILES\")\n",
    "#     parser.add_argument(\"--outfile\", type=str, default=os.path.join(os.getcwd(), \"phakin_output.csv\"),\n",
    "#                         help=\"location and file name for output\")\n",
    "#     parser.add_argument(\"--smiles_col\", type=str, default=\"SMILES\",\n",
    "#                         help=\"column name containing SMILES of interest\"),\n",
    "#     parser.add_argument(\"--ad\", action=\"store_true\",\n",
    "#                         help=\"calculate the AD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Molecule is within the AD: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the AD data from the .pkl file\n",
    "ad_file_path = \"../models/binary_AD.pkl\"  # Replace with your .pkl file path\n",
    "with open(ad_file_path, 'rb') as f:\n",
    "    ad_data = pickle.load(f)\n",
    "\n",
    "# Process the query molecule\n",
    "query_smiles = \"C1=NC(=NC(=O)N1C2C(C(C(O2)CO)O)O)N\"  # Example query molecule (Benzene)\n",
    "query_mol = Chem.MolFromSmiles(query_smiles)\n",
    "query_fp = np.array(AllChem.GetMorganFingerprintAsBitVect(query_mol, radius=2, nBits=2048, useFeatures=False))\n",
    "\n",
    "# Convert query_fp to 2D array for cdist\n",
    "query_fp_2d = query_fp[np.newaxis, :]  # Makes it 2-dimensional\n",
    "\n",
    "# Check if the query molecule is within the AD\n",
    "is_within_ad = calc_ad(query_fp_2d, ad_data)\n",
    "print(f\"Molecule is within the AD: {is_within_ad.any()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\ricar\\\\Documents\\\\GitHub\\\\dev-tox\\\\dev_tox', 'C:\\\\Program Files\\\\PerkinElmerInformatics\\\\ChemOffice2021\\\\ChemScript\\\\Lib', 'c:\\\\Users\\\\ricar\\\\anaconda3\\\\envs\\\\rdkit_env\\\\python311.zip', 'c:\\\\Users\\\\ricar\\\\anaconda3\\\\envs\\\\rdkit_env\\\\DLLs', 'c:\\\\Users\\\\ricar\\\\anaconda3\\\\envs\\\\rdkit_env\\\\Lib', 'c:\\\\Users\\\\ricar\\\\anaconda3\\\\envs\\\\rdkit_env', '', 'C:\\\\Users\\\\ricar\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\ricar\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\ricar\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\ricar\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\ricar\\\\anaconda3\\\\envs\\\\rdkit_env\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelling-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
